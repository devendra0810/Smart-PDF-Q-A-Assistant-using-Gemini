{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be241715",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-20T09:00:39.832614Z",
     "iopub.status.busy": "2025-04-20T09:00:39.831826Z",
     "iopub.status.idle": "2025-04-20T09:00:41.558433Z",
     "shell.execute_reply": "2025-04-20T09:00:41.557448Z"
    },
    "papermill": {
     "duration": 1.731996,
     "end_time": "2025-04-20T09:00:41.559855",
     "exception": false,
     "start_time": "2025-04-20T09:00:39.827859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dataset/Smart_PDF_QA_Sample.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "153f881a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T09:00:41.565814Z",
     "iopub.status.busy": "2025-04-20T09:00:41.565419Z",
     "iopub.status.idle": "2025-04-20T09:00:57.240397Z",
     "shell.execute_reply": "2025-04-20T09:00:57.239221Z"
    },
    "papermill": {
     "duration": 15.679792,
     "end_time": "2025-04-20T09:00:57.242242",
     "exception": false,
     "start_time": "2025-04-20T09:00:41.562450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain langchain-community langchain-google-genai pypdf faiss-cpu google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc9bc9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T09:00:57.249653Z",
     "iopub.status.busy": "2025-04-20T09:00:57.249333Z",
     "iopub.status.idle": "2025-04-20T09:00:57.472939Z",
     "shell.execute_reply": "2025-04-20T09:00:57.472106Z"
    },
    "papermill": {
     "duration": 0.229108,
     "end_time": "2025-04-20T09:00:57.474559",
     "exception": false,
     "start_time": "2025-04-20T09:00:57.245451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53594d5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T09:00:57.481571Z",
     "iopub.status.busy": "2025-04-20T09:00:57.481271Z",
     "iopub.status.idle": "2025-04-20T09:00:59.157695Z",
     "shell.execute_reply": "2025-04-20T09:00:59.156737Z"
    },
    "papermill": {
     "duration": 1.682065,
     "end_time": "2025-04-20T09:00:59.159554",
     "exception": false,
     "start_time": "2025-04-20T09:00:57.477489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = PyPDFLoader(\"/kaggle/input/dataset/Smart_PDF_QA_Sample.pdf\")  # Replace with your PDF filename\n",
    "pages = loader.load()\n",
    "\n",
    "\n",
    "splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = splitter.split_documents(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412d8b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T09:00:59.167009Z",
     "iopub.status.busy": "2025-04-20T09:00:59.166025Z",
     "iopub.status.idle": "2025-04-20T09:01:01.674786Z",
     "shell.execute_reply": "2025-04-20T09:01:01.673858Z"
    },
    "papermill": {
     "duration": 2.514207,
     "end_time": "2025-04-20T09:01:01.676678",
     "exception": false,
     "start_time": "2025-04-20T09:00:59.162471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "embedding = GoogleGenerativeAIEmbeddings(api_key=GOOGLE_API_KEY, model=\"models/embedding-001\")\n",
    "\n",
    "db = FAISS.from_documents(docs, embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d265da6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T09:01:01.684497Z",
     "iopub.status.busy": "2025-04-20T09:01:01.683494Z",
     "iopub.status.idle": "2025-04-20T09:01:01.692978Z",
     "shell.execute_reply": "2025-04-20T09:01:01.692052Z"
    },
    "papermill": {
     "duration": 0.014919,
     "end_time": "2025-04-20T09:01:01.694587",
     "exception": false,
     "start_time": "2025-04-20T09:01:01.679668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key=GOOGLE_API_KEY, temperature=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "491eb3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T09:01:01.702731Z",
     "iopub.status.busy": "2025-04-20T09:01:01.702431Z",
     "iopub.status.idle": "2025-04-20T09:01:03.468052Z",
     "shell.execute_reply": "2025-04-20T09:01:03.466881Z"
    },
    "papermill": {
     "duration": 1.772004,
     "end_time": "2025-04-20T09:01:03.469546",
     "exception": false,
     "start_time": "2025-04-20T09:01:01.697542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/2665130334.py:4: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
      "/tmp/ipykernel_13/2665130334.py:13: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(input_documents=relevant_docs, question=query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Answer: This document is an introduction to Artificial Intelligence (AI). AI is about making machines that can think and learn like humans. These machines can do things like understand speech, make decisions, and translate languages.\n",
      "\n",
      "There are different types of AI:\n",
      "*   Narrow AI: Good at one specific task.\n",
      "*   General AI: AI with human-like intelligence (but doesn't exist yet).\n",
      "*   Super AI: AI that is much smarter than humans.\n",
      "\n",
      "AI is used in many areas, like healthcare, finance, transportation, and customer service. AI can make things more efficient, automate tasks, reduce errors, and be available all the time. However, there are also challenges like ethical concerns, job losses, privacy issues, and bias in AI.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "# Example query you want to ask about the PDF\n",
    "query = \"Summarize the PDF content in simple language\"\n",
    "\n",
    "# Perform a similarity search to get relevant docs\n",
    "relevant_docs = db.similarity_search(query)\n",
    "\n",
    "# Get the answer from the chain\n",
    "response = chain.run(input_documents=relevant_docs, question=query)\n",
    "print(\"📄 Answer:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7164150,
     "sourceId": 11437258,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.188341,
   "end_time": "2025-04-20T09:01:04.493804",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-20T09:00:35.305463",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
